import os
import json
import numpy as np
import pandas as pd

ECG_TOKEN = "<|extra_0|>" 
INSTRUCTION_TEMPLATE = f"è¯·ä»”ç»†è§‚å¯Ÿæä¾›çš„{ECG_TOKEN}ä¿¡å·ã€‚ä½ è®¤ä¸ºæ‚£è€…æ˜¯å¦æ‚£æœ‰å¿ƒæˆ¿é¢¤åŠ¨ï¼ˆAFï¼‰ï¼Ÿè¯·ç›´æ¥å›ç­”â€˜æ˜¯â€™æˆ–â€˜å¦â€™ã€‚"

ANSWER_AF = "æœ‰æˆ¿é¢¤ã€‚" # å¯¹åº”æ ‡ç­¾ 'A'
ANSWER_NORMAL = "æ— æˆ¿é¢¤ã€‚" # å¯¹åº”æ ‡ç­¾ 'N', 'O', '~'

def label_to_response(label_char):
    """å°†å­—ç¬¦æ ‡ç­¾æ˜ å°„ä¸ºæŒ‡ä»¤å›ç­”æ–‡æœ¬"""
    # 'A' è¢«è§†ä¸º 1 (AF)ï¼Œå…¶ä»–è§†ä¸º 0 (Non-AF)
    return ANSWER_AF if label_char == 'A' else ANSWER_NORMAL

def generate_instruction_metadata(base_dir, cv_indices, output_json_file):
    """
    æ ¹æ® K-Fold CSV æ–‡ä»¶ç”Ÿæˆå¤šæ¨¡æ€æŒ‡ä»¤æ•°æ®é›†å…ƒæ•°æ®ã€‚
    Args:
        base_dir (str): '/Dataset' çš„çˆ¶ç›®å½•è·¯å¾„ã€‚
        cv_indices (list): æƒ³è¦åŒ…å«çš„ K-Fold æŠ˜æ•°åˆ—è¡¨ (ä¾‹å¦‚ [0, 1, 2, 3, 4])ã€‚
    """
    instruction_data = []
    cv_path = os.path.join(base_dir, 'cv')

    for i in cv_indices:
        csv_file = os.path.join(cv_path, f'cv{i}.csv')
        if not os.path.exists(csv_file):
            print(f"Warning: {csv_file} not found. Skipping fold {i}.")
            continue

        data = pd.read_csv(csv_file)
        for row in data.values:
            file_name = row[1] # ä¾‹å¦‚ 'A0001'
            label_char = row[2] # ä¾‹å¦‚ 'A' æˆ– 'N'

            response = label_to_response(label_char)

            # ğŸ’¥ ä¿®æ­£ 2ï¼šINSTRUCTION_TEMPLATE ç°åœ¨å·²ç»åŒ…å«äº†æ­£ç¡®çš„ ECG_TOKEN
            # ç§»é™¤å¤šä½™çš„æ›¿æ¢æ“ä½œ
            instruction_with_token = INSTRUCTION_TEMPLATE 

            # æ„é€ å®Œæ•´çš„è¾“å…¥åºåˆ—æ–‡æœ¬ (æ ¼å¼ä¸ MultimodalDataset ä¸­ç¡¬ç¼–ç çš„åˆ†éš”ç¬¦ä¸€è‡´)
            full_text = f"æŒ‡ä»¤: {instruction_with_token}\nç­”æ¡ˆ: {response}"

            entry = {
                "file_name": file_name,
                "instruction": instruction_with_token,
                "response": response,
                "full_text": full_text,# å®Œæ•´æ–‡æœ¬ç”¨äº Tokenizer
                "label_char": label_char
            }
            instruction_data.append(entry)

    # å†™å…¥ JSON æ–‡ä»¶
    with open(output_json_file, 'w', encoding='utf-8') as f:
        json.dump(instruction_data, f, ensure_ascii=False, indent=4)

    print(f"æŒ‡ä»¤æ•°æ®é›†å…ƒæ•°æ®å·²ä¿å­˜åˆ° {output_json_file}")
    print(f"æ€»æ ·æœ¬æ•°: {len(instruction_data)}")


# ä½¿ç”¨:
if __name__ == '__main__':
    # ç¡®ä¿ BASE_PATH æ˜¯ /Dataset çš„çˆ¶ç›®å½•
    BASE_PATH = os.path.abspath(os.path.join(os.path.dirname(__file__), '../Dataset'))
     
    # JSON æ–‡ä»¶å°†ä¿å­˜åœ¨ /Dataset/MMID/
    OUTPUT_JSON_FILE = os.path.join(BASE_PATH, 'MMID/multimodal_instruction_data.json')
    output_dir = os.path.dirname(OUTPUT_JSON_FILE)
    os.makedirs(output_dir, exist_ok=True)

    # åŒ…å«æ‰€æœ‰ 5 æŠ˜çš„æ•°æ®
    generate_instruction_metadata(BASE_PATH, cv_indices=[0, 1, 2, 3, 4], output_json_file=OUTPUT_JSON_FILE)